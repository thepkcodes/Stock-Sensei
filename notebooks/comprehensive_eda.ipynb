{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Stock Market AI Agent - Comprehensive EDA\n",
    "\n",
    "This notebook performs exploratory data analysis on:\n",
    "1. Stock price data\n",
    "2. News sentiment data\n",
    "3. Macroeconomic indicators\n",
    "\n",
    "**Objective**: Understand the data structure, distributions, and relationships to inform feature engineering and modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "stock_data = pd.read_csv('../data/stock_prices.csv')\n",
    "sentiment_data = pd.read_csv('../data/news_sentiment.csv')\n",
    "macro_data = pd.read_csv('../data/macro_indicators.csv')\n",
    "\n",
    "print(f\"‚úÖ Stock data loaded: {stock_data.shape}\")\n",
    "print(f\"‚úÖ Sentiment data loaded: {sentiment_data.shape}\")\n",
    "print(f\"‚úÖ Macro data loaded: {macro_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "sentiment_data['Date'] = pd.to_datetime(sentiment_data['Date'])\n",
    "macro_data['Date'] = pd.to_datetime(macro_data['Date'])\n",
    "\n",
    "print(\"Date columns converted to datetime format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Stock Price Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about stock data\n",
    "print(\"üìä Stock Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {stock_data.shape}\")\n",
    "print(f\"Date range: {stock_data['Date'].min()} to {stock_data['Date'].max()}\")\n",
    "print(f\"Number of unique tickers: {stock_data['Ticker'].nunique()}\")\n",
    "print(f\"Tickers: {sorted(stock_data['Ticker'].unique())}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock data statistics\n",
    "print(\"üìà Stock Data Statistics\")\n",
    "stock_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values in Stock Data\")\n",
    "missing_stock = stock_data.isnull().sum()\n",
    "print(missing_stock)\n",
    "print(f\"\\nTotal missing values: {missing_stock.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot closing prices for top 10 stocks by market cap\n",
    "top_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'UNH', 'JNJ', 'JPM']\n",
    "top_stock_data = stock_data[stock_data['Ticker'].isin(top_stocks)]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, ticker in enumerate(top_stocks):\n",
    "    ticker_data = top_stock_data[top_stock_data['Ticker'] == ticker]\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(ticker_data['Date'], ticker_data['close'])\n",
    "    plt.title(f'{ticker} Stock Price')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Price ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(stock_data['volume'], bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Trading Volume')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stock_data.boxplot(column='volume', ax=plt.gca())\n",
    "plt.title('Trading Volume Box Plot')\n",
    "plt.ylabel('Volume')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 3. News Sentiment Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about sentiment data\n",
    "print(\"üì∞ Sentiment Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {sentiment_data.shape}\")\n",
    "print(f\"Date range: {sentiment_data['Date'].min()} to {sentiment_data['Date'].max()}\")\n",
    "print(f\"Number of unique tickers: {sentiment_data['Ticker'].nunique()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment statistics\n",
    "print(\"üìä Sentiment Data Statistics\")\n",
    "sentiment_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in sentiment data\n",
    "print(\"üîç Missing Values in Sentiment Data\")\n",
    "missing_sentiment = sentiment_data.isnull().sum()\n",
    "print(missing_sentiment)\n",
    "print(f\"\\nTotal missing values: {missing_sentiment.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(sentiment_data['sentiment_score'], bins=50, alpha=0.7, color='skyblue')\n",
    "plt.title('Distribution of Sentiment Scores')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.7, label='Neutral')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sentiment_data.boxplot(column='sentiment_score', ax=plt.gca())\n",
    "plt.title('Sentiment Score Box Plot')\n",
    "plt.ylabel('Sentiment Score')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(sentiment_data['news_count'], bins=20, alpha=0.7, color='lightgreen')\n",
    "plt.title('Distribution of News Count')\n",
    "plt.xlabel('News Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment by ticker (top 10 stocks)\n",
    "top_sentiment = sentiment_data[sentiment_data['Ticker'].isin(top_stocks)]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=top_sentiment, x='Ticker', y='sentiment_score')\n",
    "plt.title('Sentiment Score Distribution by Top 10 Stocks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.axhline(0, color='red', linestyle='--', alpha=0.7, label='Neutral')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment over time for selected stocks\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "selected_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA']\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ticker in enumerate(selected_stocks):\n",
    "    ticker_sentiment = sentiment_data[sentiment_data['Ticker'] == ticker]\n",
    "    # Resample to monthly average for cleaner visualization\n",
    "    monthly_sentiment = ticker_sentiment.set_index('Date').resample('M')['sentiment_score'].mean()\n",
    "    \n",
    "    axes[i].plot(monthly_sentiment.index, monthly_sentiment.values)\n",
    "    axes[i].set_title(f'{ticker} - Monthly Average Sentiment')\n",
    "    axes[i].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].set_ylabel('Sentiment Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 4. Macroeconomic Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info about macro data\n",
    "print(\"üèõÔ∏è Macroeconomic Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {macro_data.shape}\")\n",
    "print(f\"Date range: {macro_data['Date'].min()} to {macro_data['Date'].max()}\")\n",
    "print(f\"Columns: {list(macro_data.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "macro_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro data statistics\n",
    "print(\"üìä Macroeconomic Data Statistics\")\n",
    "macro_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in macro data\n",
    "print(\"üîç Missing Values in Macro Data\")\n",
    "missing_macro = macro_data.isnull().sum()\n",
    "print(missing_macro)\n",
    "print(f\"\\nTotal missing values: {missing_macro.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macro indicators over time\n",
    "macro_cols = [col for col in macro_data.columns if col != 'Date']\n",
    "n_cols = len(macro_cols)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(macro_cols):\n",
    "    # Resample to monthly for cleaner visualization\n",
    "    monthly_data = macro_data.set_index('Date').resample('M')[col].mean()\n",
    "    \n",
    "    axes[i].plot(monthly_data.index, monthly_data.values)\n",
    "    axes[i].set_title(f'{col.replace(\"_\", \" \").title()}')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].set_ylabel(col.replace('_', ' ').title())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of macro indicators\n",
    "macro_numeric = macro_data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = macro_numeric.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Macroeconomic Indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 5. Cross-Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data coverage analysis\n",
    "print(\"üìÖ Data Coverage Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get date ranges for each dataset\n",
    "stock_dates = pd.date_range(stock_data['Date'].min(), stock_data['Date'].max())\n",
    "sentiment_dates = pd.date_range(sentiment_data['Date'].min(), sentiment_data['Date'].max())\n",
    "macro_dates = pd.date_range(macro_data['Date'].min(), macro_data['Date'].max())\n",
    "\n",
    "print(f\"Stock data: {len(stock_dates)} days ({stock_data['Date'].min().date()} to {stock_data['Date'].max().date()})\")\n",
    "print(f\"Sentiment data: {len(sentiment_dates)} days ({sentiment_data['Date'].min().date()} to {sentiment_data['Date'].max().date()})\")\n",
    "print(f\"Macro data: {len(macro_dates)} days ({macro_data['Date'].min().date()} to {macro_data['Date'].max().date()})\")\n",
    "\n",
    "# Find overlapping dates\n",
    "overlap_start = max(stock_data['Date'].min(), sentiment_data['Date'].min(), macro_data['Date'].min())\n",
    "overlap_end = min(stock_data['Date'].max(), sentiment_data['Date'].max(), macro_data['Date'].max())\n",
    "print(f\"\\nOverlapping period: {overlap_start.date()} to {overlap_end.date()}\")\n",
    "print(f\"Overlapping days: {(overlap_end - overlap_start).days + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample correlation analysis between stock prices and sentiment for AAPL\n",
    "aapl_stock = stock_data[stock_data['Ticker'] == 'AAPL'].copy()\n",
    "aapl_sentiment = sentiment_data[sentiment_data['Ticker'] == 'AAPL'].copy()\n",
    "\n",
    "# Merge AAPL stock and sentiment data\n",
    "aapl_merged = pd.merge(aapl_stock[['Date', 'close']], \n",
    "                       aapl_sentiment[['Date', 'sentiment_score']], \n",
    "                       on='Date', how='inner')\n",
    "\n",
    "if not aapl_merged.empty:\n",
    "    # Calculate correlation\n",
    "    correlation = aapl_merged['close'].corr(aapl_merged['sentiment_score'])\n",
    "    print(f\"AAPL Stock Price vs Sentiment Correlation: {correlation:.3f}\")\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(aapl_merged['sentiment_score'], aapl_merged['close'], alpha=0.6)\n",
    "    plt.xlabel('Sentiment Score')\n",
    "    plt.ylabel('AAPL Closing Price ($)')\n",
    "    plt.title(f'AAPL: Stock Price vs Sentiment Score (Correlation: {correlation:.3f})')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(aapl_merged['sentiment_score'], aapl_merged['close'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(aapl_merged['sentiment_score'], p(aapl_merged['sentiment_score']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\nelse:\n    print(\"No overlapping data found for AAPL stock and sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "print(\"üîç Data Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def assess_data_quality(df, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"  Duplicate rows: {df.duplicated().sum()}\")\n",
    "    if 'Date' in df.columns:\n",
    "        print(f\"  Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "        print(f\"  Unique dates: {df['Date'].nunique()}\")\n",
    "\nassess_data_quality(stock_data, \"Stock Data\")\nassess_data_quality(sentiment_data, \"Sentiment Data\")\nassess_data_quality(macro_data, \"Macro Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Recommendations\n",
    "\n",
    "Based on the EDA performed above, here are the key insights:\n",
    "\n",
    "### Stock Data Insights:\n",
    "- ‚úÖ **Coverage**: Good coverage with ~61K records across 49 tickers\n",
    "- ‚úÖ **Quality**: No missing values in core price data\n",
    "- üìä **Patterns**: Different stocks show varying price patterns and volatility\n",
    "- üìà **Volume**: Trading volumes vary significantly across stocks\n",
    "\n",
    "### Sentiment Data Insights:\n",
    "- ‚úÖ **Coverage**: Comprehensive with ~65K records\n",
    "- üìä **Distribution**: Sentiment scores are normally distributed around neutral (0)\n",
    "- üéØ **Variation**: Different stocks have different sentiment patterns\n",
    "- üì∞ **News Count**: Average of 3 news articles per day per stock\n",
    "\n",
    "### Macro Data Insights:\n",
    "- ‚úÖ **Indicators**: 6 key economic indicators included\n",
    "- üìä **Trends**: Each indicator shows realistic economic patterns\n",
    "- üîó **Correlations**: Some correlations between economic indicators\n",
    "\n",
    "### Recommendations for Next Steps:\n",
    "1. **Feature Engineering**: Create technical indicators, lagged variables, and rolling statistics\n",
    "2. **Data Merging**: Merge all datasets on Date and Ticker with proper handling of missing values\n",
    "3. **Forward Fill**: Implement forward fill for sentiment data as specified\n",
    "4. **Model Selection**: Consider both traditional ML (Random Forest, XGBoost) and deep learning (LSTM) approaches\n",
    "5. **Target Variable**: Define prediction target (next day/week closing price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
